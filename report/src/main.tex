%! Author = metametamoon
%! Date = 1/27/25

% Preamble
\documentclass[11pt]{article}

% Packages
\usepackage{amsmath}
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{caption}

\newcommand{\realpositive}{\mathbb{R}_{\geqslant 0}}
\DeclareMathOperator*{\argmin}{arg\,min}
% Document
\begin{document}
    \section{Мотивация}
    Во многих областях искусственного интеллекта естественным образом появляется планирования путей на больших графах.
    Большая часть исследований в этой задаче покрывает задачу в случае, когда граф нам целиком известен заранее.
    Однако многим системам приходится сталкиваться с динамическими изменениями в графе и приходиться адаптироваться к изменившимся условиям, поскольку предыдущий итог планирования может потерять актуальность


    \section{Постановка задачи}
    Пусть нам дан граф $G = (V, E)$, где $V$ --- конечное множество вершин, $E \subset V \times V \times \realpositive$ --- множество взвешенных ребер.
    При этом будем считать, что в графе нет кратных ребер, ввиду чего можно ввести функцию веса ребра $w: V \times V \rightarrow {\realpositive \lor \infty}$
    Путем в графе будем называть конечную последовательность $A = [v_1, v_2, \dots, v_n]$ такую, что для каждого $i = 1, \dots, n-1$: $w(v_i, v_{i+1}) \neq \infty$ для некоторого $w \in \mathbb{R}_{\geqslant 0}$.
    Множество конечных последовательностей вершин мы будем обозначать $P = P(V)$.
    Весом пути мы будем называть выражение $w(A) = \sum_{i = 1}^{n-1} w(v_i, v_{i+1})$.
    Началом пути мы будем называть при этом первый элемент последовательности и обозначать $s(A)$, а концом пути --- последний элемент последовательности, и обозначать $d(A)$.

    Мы хотим решать задачу минимального пути --- нам даны вершины $s, d \in V$  (далее мы считаем, что $s, d, V$ фиксированы) и мы должны найти
    $$A_{plan}= \argmin_{\substack{A \subset V \text{ --- путь в } G \\ s(A) = s \\ d(A) = d}} w(A).$$
    Мы будем также говорить тогда, что $A = \mathtt{optpath}(G, s, d)$.

    \pagebreak
    \newcommand{\fplan}{\mathtt{plan}}
    \newcommand{\fextract}{\mathtt{extract}}
    \newcommand{\fempty}{\mathtt{empty}}
    Сформулируем более точно алгоритмическую задачу.
    На $i$-ом шаге мы получаем информацию $E_i \subset V \times V \times \realpositive \lor \infty$ об изменении весов ребер в графе.
    Тогда \textit{алгоритмом для решения задачи долгосрочного планирования} мы будем называть тройку $(T, \fplan, \fextract)$ из произвольного множества и двух вычислимых фукнций соответственно, такую что:
    \begin{align*}
        &\fempty \in T \\
        &\fplan: E \times T \rightarrow T \\
        &\fextract: T \rightarrow P(V) \\
        &\fextract(\fplan(E, \fempty)) = \mathtt{optpath}(G, s, d) \\
        &\fextract(t_0) = \mathtt{optpath}((V, E'), s, d) \rightarrow \\
        &\qquad \fextract(\fplan(E_{new}, t_0)) = \mathtt{optpath}((V, E' \leftarrow E_{new}), s, d)
    \end{align*}

    Мы будем применять алгоритм в следующем коде (который следует рассматривать как синтаксический сахар над машиной Тьюринга):
    \begin{verbatim}
active_plan = empty
for i in 1..n:
     e_new_i = get_e_new_i()
     active_plan = plan(e_new_i, active_plan)
     shortest_path = extract(active_plan)
    \end{verbatim}
    Мы хотим минимизировать число итераций алгоритма $\fplan$ и $\fextract$ в ходе исполнения псевдокода выше.



    \begin{verbatim}
bool A*(start, goal):
     U = {}
     Q = {}
     Q.push(start)
     g[start] = 0
     f[start] = g[start] + h(start)
     while Q.size() != 0
          current = Q.top() // vertex with minimal f-value
          if current == goal
               return true  // path found
          Q.remove(current)
          U.push(current)
          for v : N(current)
               // d(current, v) --- cost of passing from current to v
               tentativeScore = g[current] + d(current, v)
               if v in U and tentativeScore >= g[v]
                    continue
               if v in U or tentativeScore < g[v]
                    parent[v] = current
                    g[v] = tentativeScore
                    f[v] = g[v] + h(v)
                    if v in Q
                         Q.push(v)
     return false
    \end{verbatim}


    \section{Метод решения}

    Несложно заметить, что реализация функции \(\fplan\), которая заново находит кратчайший путь в графе с обновленными ребрами, является решением нашей задачи.
    Однако оптимальность этого решения оставляет желать лучшего: даже при небольших изменениях ребер в графе нам придется выполнять заново всю процедуру планирования.
    В связи с этим хочется использовать \textit{инкрементальные}, которые во время планирования сохраняют полезную в дальнейшем информацию, чтобы ее затем эффективно переиспользовать в новой задаче планирования.
    Такие алгоритмы уже есть --- например, Dynamic SWSF-FP~\cite{RAMALINGAM1996267}.

    С другой стороны, использование эвристик в задачах поиска дает на практике очень существенное преимущество, в связи с чем широко используется.
    Наиболее популярным алгоритмом для задачи планирования с использованием эвристик является алгоритм $A^*$~\cite{Nilsson1971ProblemsolvingMI}.
    Однако алгоритм $A^*$ сам по себе не является инкрементальным в связи с чем его использование в нашей задаче приведет к повторному планированию крайне часто.

    Мы хотим объединить эти два подхода --- использовать эвристики для направления поиска и использовать инкрементальность для оптимального пересчета решения при появлении новых данных.
    Для этого мы переиспользуем идею из алгоритма Dynamic SWSF-FP.
    Как мы знаем, уравнение \[ g^*(v) = \begin{cases}
                                            0 &  v == s\\
                                            \min_{v' \in neighbors(v)} (w(v, v') + g^*(v')) \\
    \end{cases} \]
    задает оценку $g^*(v)$ кратчайшего пути от $s$ до произвольной вершины $v$.
    Мы будем для каждой вершины поддерживать оценку веса кратчайшего пути $g$ в том же значении, как и в алгоритме $A^*$, а также
    величину \[rhs(v) = \min_{v' \in neighbors(v)} (w(v, v') + g(v')). \]
    Несложно заметить, что если во всех вершинах $rhs(v) = g(v)$, то $g(v) = g^*(v)$ для всех вершин $v$.
    Будем называть вершину $v$ \textit{неконсистентной}, если $rhs(v) \neq g(v)$.
    В ходе алгоритма мы будем итеративно исправлять неконсистентность, пока ее исправление может привести к нахождению кратчайшего пути.

    Заметим, что при изменении веса ребер у нас меняются $rhs$-значения у вершин, связанных с этими ребрами.
    По нашему алгоритму, мы будем исправлять неконсистентность лишь у необходимого количества вершин, начиная с вершин, находящихся рядом с измененными ребрами.

    \textbf{\LARGE Сюда надо вставить псевдокод LPA star.}


    \section{Алгоритм $D^*$ lite}
    Возможность пересчитывать кратчайшие пути позволяет нам решать следующую задачу.
    Пусть у нас есть агент с ограниченным зрением, который должен дойти до некоторой точки на карте.
    Изначально у него нет никакой карты местности, но он обновляет свои данные, когда препятствия попадают в его поле зрения.
    Агент всегда хочет идти по оптимальному пути к цели, но информация о препятствиях будет заставлять его перестраивать план.

    В этой ситуации можно использовать алгоритм $LPA^*$ следующим образом.
    Агент может на очередном шаге строить кратчайший путь от цели до себя, основываясь на известных ему данных.
    После очередного шага он использует информацию о полученных препятствиях, чтобы обновить план кратчайшего пути от цели до себя.


    \section{Экспериментальные исследования}

    Мы будем исследовать алгоритм $D^* lite$ в задаче поиска пути на карте с ограниченной видимостью.
    Для этого мы используем карты с датасета MovingAI~\cite{sturtevant2012benchmarks}.
    Мы используем 4 карты, которые обобщают реально встречающиеся топологии у агентов в реальной жизни: план этажа, город, разные виды лабиринтов.
    \begin{figure}
        \centering
        \begin{subfigure}[b]{0.24\textwidth}
            \centering
            \includegraphics[width=\textwidth]{../maps/Labyrinth}
            \caption{Labyrinth}
            \label{fig:y equals x}
        \end{subfigure}
        \hfill
        \begin{subfigure}[b]{0.24\textwidth}
            \centering
            \includegraphics[width=\textwidth]{../maps/den401d}
            \caption{den401d}
        \end{subfigure}
        \hfill
        \begin{subfigure}[b]{0.24\textwidth}
            \centering
            \includegraphics[width=\textwidth]{../maps/brc504d}
            \caption{brc504d}
        \end{subfigure}
        \begin{subfigure}[b]{0.24\textwidth}
            \centering
            \includegraphics[width=\textwidth]{../maps/NewYork_1_256}
            \caption{NewYork_1_256}
        \end{subfigure}
        \caption{Three simple graphs}
        \label{fig:three graphs}
    \end{figure}

    Для каждой карты мы равномерно выберем хотя бы 100 сценариев, выбирая каждый 5 сценарий в файле сценариев, и запустим на них агента с различными радиусами видимости.
    Будем отслеживать только производительность, считая, что память не является узким местом в областях применения данного алгоритма.
    В качестве метрик мы возьмем время работы алгоритма на карте, а также для воспроизводимости результатов число операций, модифицирующих очередь с приоритетом (во всех алгоритмах мы использовали для очереди с приоритетом одну и ту же структуру данных) и количество чтений/записей полей вершины.



    \section{Литература}
    \bibliography{main}
    \bibliographystyle{plain}

\end{document}